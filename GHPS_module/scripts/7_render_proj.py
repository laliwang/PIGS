# 2025-04-29 用于从mesh上渲染深度图像，然后使用这些深度图像投影点云 adopted from scannetpp
import argparse
import os
import cv2
import sys
from pathlib import Path
import open3d as o3d

import imageio
import numpy as np
from tqdm import tqdm
from tqdm import trange
from natsort import natsorted
import json
import yaml
try:
    import renderpy
except ImportError:
    print("renderpy not installed. Please install renderpy from https://github.com/liu115/renderpy")
    sys.exit(1)

def read_txt_to_list(file_path):
    with open(file_path, 'r') as file:
        lines = file.readlines()
    # 去掉每行的换行符并返回列表
    return [line.strip() for line in lines]

def read_files(directory, endtxt):
    file_paths = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(endtxt)]
    file_list = natsorted(file_paths)
    return file_list

def compute_normals(pcd, tran, search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30)):
    pcd.estimate_normals(search_param=search_param)
    try:
        pcd.orient_normals_towards_camera_location(camera_location=[tran[0], tran[1], tran[2]])
    except Exception as e:
        return None
    return pcd

# rendered depth projection for point cloud
def project_mask_pc(rgb_input, depth_input, pose_input, K_input, max_depth=10, filter_outlier=False):
    rgb_array = cv2.imread(rgb_input)
    rgb_array = cv2.cvtColor(rgb_array, cv2.COLOR_BGR2RGB)
    # rgb_array = cv2.resize(rgb_array, (640, 480), cv2.INTER_AREA)
    # print(rgb_array.shape)
    depth_array = cv2.imread(depth_input, -1)
    depth_array = depth_array / 1000.0
    if max_depth > 0:
        depth_array[depth_array > max_depth] = 0
    fx, fy, cx, cy = K_input[0,0],K_input[1,1],K_input[0,2],K_input[1,2]
    # Convert to 3D coordinates
    mask_valid = (depth_array > 0)
    v, u = np.where(mask_valid)
    depth_mask = depth_array[mask_valid]
    rgb_mask = (rgb_array[mask_valid]).reshape(-1,3)
    x = (u - cx) * depth_mask / fx
    y = (v - cy) * depth_mask / fy
    z = depth_mask
    points = np.stack((x, y, z), axis=-1)
    points = points.reshape(-1, 3)
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points)
    pcd.colors = o3d.utility.Vector3dVector(rgb_mask / 255.0)
    pose = np.loadtxt(pose_input)
    pcd = pcd.transform(pose)
    pcd = pcd.voxel_down_sample(voxel_size=0.025)
    if filter_outlier:
        cl, ind = pcd.remove_radius_outlier(nb_points=10, radius=0.05)
        pcd = pcd.select_by_index(ind)
    # inlier_pcd = inlier_pcd.voxel_down_sample(voxel_size=0.025)
    if len(pcd.points) == 0:
        return None
    else:
        pcd = compute_normals(pcd, pose[:3,3])
        return pcd

def main(args):
    depth_model = args.depth_model
    voxel_size = args.voxel_size
    root_path = args.data_folder
    near = args.near
    far = args.far

    output_dir = os.path.join(root_path, 'pyrender_debug')
    os.makedirs(output_dir, exist_ok=True)

    mesh_path = os.path.join(root_path, f'mesh/tsdf_fusion_SR_{depth_model}.ply')
    render_engine = renderpy.Render()
    print(f'Rendering depth from mesh generated by {depth_model}!')
    render_engine.setupMesh(mesh_path)

    if args.scannetpp:
        print('depth render segment for scannetpp not implemented ...')
    else:
        # depth render segment for scannet
        pose_folder = f'{root_path}/pose'
        intrinsic_path = f'{root_path}/intrinsic/intrinsic_depth.txt'
        K_input = np.loadtxt(intrinsic_path)
        pose_txt_list = read_files(pose_folder, ".txt")
        render_engine.setupCamera(
            480, 640,
            K_input[0,0], K_input[1,1], K_input[0,2], K_input[1,2],
            'PINHOLE',
            None,      # Distortion parameters np.array([k1, k2, k3, k4]) or np.array([k1, k2, p1, p2])
        )
        depth_dir = Path(output_dir) / f"render_depth_{depth_model}"
        depth_dir.mkdir(parents=True, exist_ok=True)
        for i in trange(len(pose_txt_list)):
            img_id = int(pose_txt_list[i].split('/')[-1].split(".")[0])
            world_to_camera = np.linalg.inv(np.loadtxt(pose_txt_list[i]))
            rgb, depth, vert_indices = render_engine.renderAll(world_to_camera, near, far)
            rgb = rgb.astype(np.uint8)
            depth = (depth.astype(np.float32) * 1000).clip(0, 65535).astype(np.uint16)
            depth_name = f"{img_id}.png"
            imageio.imwrite(depth_dir / depth_name, depth)
    
    # project final point cloud for maskclustering
    rgb_input = f'{root_path}/color'
    depth_input = str(depth_dir)
    pose_input = f'{root_path}/pose'
    K_path = f'{root_path}/intrinsic/intrinsic_depth.txt'

    rgb_list = read_files(rgb_input, ".jpg")
    depth_list = read_files(depth_input, ".png")
    pose_list = read_files(pose_input, ".txt")
    K_input = np.loadtxt(K_path)
    pcd_save = o3d.geometry.PointCloud()

    for i in trange(0,len(depth_list)):
        pcd = project_mask_pc(rgb_list[i], depth_list[i], pose_list[i], K_input, filter_outlier=True)
        if pcd is not None:
            pcd_save += pcd
    pcd_save = pcd_save.voxel_down_sample(voxel_size=voxel_size)
    o3d.io.write_point_cloud(f"{root_path}/mesh/points3d_{depth_model}_proj.ply", pcd_save)
    print(f'points3d_{depth_model}_proj.ply saved ok!')

if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("--data_folder", type=str, required=True)
    p.add_argument("--depth_model", type=str, required=True)
    p.add_argument("--scannetpp", action="store_true", default=False)
    p.add_argument("--voxel_size", type=float, default=0.025, help="voxel size for downsampling")
    p.add_argument("--near", type=float, default=0.05)
    p.add_argument("--far", type=float, default=10.0)
    args = p.parse_args()

    main(args)